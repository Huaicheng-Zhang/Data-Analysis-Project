{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('C:/Users/THINKPAD/Desktop/task/ai-interview-code/data.csv')\n",
    "\n",
    "# remove lines with label 'undefined' (incomplete entries)\n",
    "data = data.dropna()\n",
    "\n",
    "# remove lines with uncertain labels such as 'live'\n",
    "data = data[~data['state'].isin(['live', 'canceled', 'suspended'])]\n",
    "\n",
    "# classMap = {'successful': 1, 'failed': 0}\n",
    "# data['state'] = data['state'].map(classMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>goal</th>\n",
       "      <th>launched</th>\n",
       "      <th>pledged</th>\n",
       "      <th>state</th>\n",
       "      <th>backers</th>\n",
       "      <th>country</th>\n",
       "      <th>usd pledged</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "      <th>usd_goal_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000002330</td>\n",
       "      <td>The Songs of Adelaide &amp; Abullah</td>\n",
       "      <td>Poetry</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>GBP</td>\n",
       "      <td>2015-10-09</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>2015-08-11 12:12:28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>0</td>\n",
       "      <td>GB</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1533.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000003930</td>\n",
       "      <td>Greeting From Earth: ZGAC Arts Capsule For ET</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>2017-09-02 04:43:57</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>15</td>\n",
       "      <td>US</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2421.0</td>\n",
       "      <td>30000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000004038</td>\n",
       "      <td>Where is Hank?</td>\n",
       "      <td>Narrative Film</td>\n",
       "      <td>Film &amp; Video</td>\n",
       "      <td>USD</td>\n",
       "      <td>2013-02-26</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>2013-01-12 00:20:50</td>\n",
       "      <td>220.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>220.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>45000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000007540</td>\n",
       "      <td>ToshiCapital Rekordz Needs Help to Complete Album</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>2012-04-16</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>2012-03-17 03:24:11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>failed</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000014025</td>\n",
       "      <td>Monarch Espresso Bar</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Food</td>\n",
       "      <td>USD</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2016-02-26 13:38:27</td>\n",
       "      <td>52375.0</td>\n",
       "      <td>successful</td>\n",
       "      <td>224</td>\n",
       "      <td>US</td>\n",
       "      <td>52375.0</td>\n",
       "      <td>52375.0</td>\n",
       "      <td>50000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               name  \\\n",
       "0  1000002330                    The Songs of Adelaide & Abullah   \n",
       "1  1000003930      Greeting From Earth: ZGAC Arts Capsule For ET   \n",
       "2  1000004038                                     Where is Hank?   \n",
       "3  1000007540  ToshiCapital Rekordz Needs Help to Complete Album   \n",
       "5  1000014025                               Monarch Espresso Bar   \n",
       "\n",
       "         category main_category currency    deadline     goal  \\\n",
       "0          Poetry    Publishing      GBP  2015-10-09   1000.0   \n",
       "1  Narrative Film  Film & Video      USD  2017-11-01  30000.0   \n",
       "2  Narrative Film  Film & Video      USD  2013-02-26  45000.0   \n",
       "3           Music         Music      USD  2012-04-16   5000.0   \n",
       "5     Restaurants          Food      USD  2016-04-01  50000.0   \n",
       "\n",
       "              launched  pledged       state  backers country  usd pledged  \\\n",
       "0  2015-08-11 12:12:28      0.0      failed        0      GB          0.0   \n",
       "1  2017-09-02 04:43:57   2421.0      failed       15      US        100.0   \n",
       "2  2013-01-12 00:20:50    220.0      failed        3      US        220.0   \n",
       "3  2012-03-17 03:24:11      1.0      failed        1      US          1.0   \n",
       "5  2016-02-26 13:38:27  52375.0  successful      224      US      52375.0   \n",
       "\n",
       "   usd_pledged_real  usd_goal_real  \n",
       "0               0.0        1533.95  \n",
       "1            2421.0       30000.00  \n",
       "2             220.0       45000.00  \n",
       "3               1.0        5000.00  \n",
       "5           52375.0       50000.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# show the distribution of 'state' samples\n",
    "print(data.groupby('state').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378661, 15)\n",
      "                 ID          goal       pledged        backers   usd pledged  \\\n",
      "count  3.786610e+05  3.786610e+05  3.786610e+05  378661.000000  3.748640e+05   \n",
      "mean   1.074731e+09  4.908079e+04  9.682979e+03     105.617476  7.036729e+03   \n",
      "std    6.190862e+08  1.183391e+06  9.563601e+04     907.185035  7.863975e+04   \n",
      "min    5.971000e+03  1.000000e-02  0.000000e+00       0.000000  0.000000e+00   \n",
      "25%    5.382635e+08  2.000000e+03  3.000000e+01       2.000000  1.698000e+01   \n",
      "50%    1.075276e+09  5.200000e+03  6.200000e+02      12.000000  3.947200e+02   \n",
      "75%    1.610149e+09  1.600000e+04  4.076000e+03      56.000000  3.034090e+03   \n",
      "max    2.147476e+09  1.000000e+08  2.033899e+07  219382.000000  2.033899e+07   \n",
      "\n",
      "       usd_pledged_real  usd_goal_real  \n",
      "count      3.786610e+05   3.786610e+05  \n",
      "mean       9.058924e+03   4.545440e+04  \n",
      "std        9.097334e+04   1.152950e+06  \n",
      "min        0.000000e+00   1.000000e-02  \n",
      "25%        3.100000e+01   2.000000e+03  \n",
      "50%        6.243300e+02   5.500000e+03  \n",
      "75%        4.050000e+03   1.550000e+04  \n",
      "max        2.033899e+07   1.663614e+08  \n"
     ]
    }
   ],
   "source": [
    "# show the dimension of input data\n",
    "print(data.shape)\n",
    "\n",
    "# dataset description\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 331462 entries, 0 to 378660\n",
      "Data columns (total 15 columns):\n",
      "ID                  331462 non-null int64\n",
      "name                331462 non-null object\n",
      "category            331462 non-null object\n",
      "main_category       331462 non-null object\n",
      "currency            331462 non-null object\n",
      "deadline            331462 non-null object\n",
      "goal                331462 non-null float64\n",
      "launched            331462 non-null object\n",
      "pledged             331462 non-null float64\n",
      "state               331462 non-null object\n",
      "backers             331462 non-null int64\n",
      "country             331462 non-null object\n",
      "usd pledged         331462 non-null float64\n",
      "usd_pledged_real    331462 non-null float64\n",
      "usd_goal_real       331462 non-null float64\n",
      "dtypes: float64(5), int64(2), object(8)\n",
      "memory usage: 40.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# information of every feature (every column)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select columns with values for feature analysis\n",
    "# x stands for trained variables, y stands for target variable\n",
    "\n",
    "x, y = data.iloc[:, [6,8,10,12,13,14]].values, data.iloc[:, 9].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "\n",
    "# use Random Forest model to find the most related features to the target\n",
    "forest = RandomForestClassifier(n_estimators = 100, random_state = 0, n_jobs = 1)\n",
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) usd_pledged_real               0.231361\n",
      " 2) pledged                        0.221913\n",
      " 3) backers                        0.191015\n",
      " 4) usd_goal_real                  0.151379\n",
      " 5) goal                           0.130362\n",
      " 6) usd pledged                    0.073971\n"
     ]
    }
   ],
   "source": [
    "# show the importance of selected features\n",
    "importances = forest.feature_importances_\n",
    "fea_labels = data.columns[[6,8,10,12,13,14]]\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for i in range(x_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (i + 1, 30, fea_labels[indices[i]], importances[indices[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(331462, 15)\n"
     ]
    }
   ],
   "source": [
    "array = data.values\n",
    "print(array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.00000000e+00   1.53395000e+03   0.00000000e+00]\n",
      " [  2.42100000e+03   3.00000000e+04   1.50000000e+01]\n",
      " [  2.20000000e+02   4.50000000e+04   3.00000000e+00]\n",
      " ..., \n",
      " [  2.00000000e+01   1.50000000e+04   1.00000000e+00]\n",
      " [  2.00000000e+02   1.50000000e+04   6.00000000e+00]\n",
      " [  5.24000000e+02   2.00000000e+03   1.70000000e+01]]\n",
      "['failed' 'failed' 'failed' ..., 'failed' 'failed' 'failed']\n"
     ]
    }
   ],
   "source": [
    "# divide our dataset into training set and testing set, and select the features according to importance\n",
    "\n",
    "x = data[[ 'usd_pledged_real', 'usd_goal_real', 'backers']].values\n",
    "y = data['state'].values\n",
    "\n",
    "# perform scalling if using SVC:\n",
    "# robust_scaler = RobustScaler()\n",
    "# x = robust_scaler.fit_transform(x)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR: 0.999823 (0.000089)\n",
      "DT: 0.999198 (0.000181)\n",
      "LDA: 0.606694 (0.002701)\n",
      "KNN: 0.999629 (0.000134)\n",
      "SVC: 0.999483 (0.001296)\n",
      "NB: 0.707951 (0.002804)\n"
     ]
    }
   ],
   "source": [
    "# building the classification models and comparing their brief performance\n",
    "\n",
    "models = []\n",
    "names = []\n",
    "results = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('DT', DecisionTreeClassifier()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('SVC', LinearSVC()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits = 10, random_state = 1)\n",
    "    cv_result = model_selection.cross_val_score(model, x_train, y_train, cv = kfold, scoring = 'accuracy')\n",
    "    results.append(cv_result)\n",
    "    names.append(name)\n",
    "    info = \"%s: %f (%f)\"% (name, cv_result.mean(), cv_result.std())\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6875 s\n",
      "0.999919548668\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     failed       1.00      1.00      1.00     59307\n",
      " successful       1.00      1.00      1.00     40132\n",
      "\n",
      "avg / total       1.00      1.00      1.00     99439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear SVC model (SVC is not considered here due to the time cost)\n",
    "# process_time() is used to calculate the running time of each model\n",
    "\n",
    "t1 = time.process_time()\n",
    "svc = LinearSVC()\n",
    "svc.fit(x_train, y_train)\n",
    "predictions = svc.predict(x_test)\n",
    "t2 = time.process_time()\n",
    "print(t2 - t1, 's')\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.640625 s\n",
      "0.99959774334\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     failed       1.00      1.00      1.00     59307\n",
      " successful       1.00      1.00      1.00     40132\n",
      "\n",
      "avg / total       1.00      1.00      1.00     99439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# K Nearest Neighbors model\n",
    "\n",
    "t1 = time.process_time()\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "predictions = knn.predict(x_test)\n",
    "t2 = time.process_time()\n",
    "print(t2 - t1, 's')\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.28125 s\n",
      "0.999265881596\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     failed       1.00      1.00      1.00     59307\n",
      " successful       1.00      1.00      1.00     40132\n",
      "\n",
      "avg / total       1.00      1.00      1.00     99439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree model\n",
    "\n",
    "t1 = time.process_time()\n",
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(x_train, y_train)\n",
    "predictions = DT.predict(x_test)\n",
    "t2 = time.process_time()\n",
    "print(t2 - t1, 's')\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.703125 s\n",
      "0.707609690363\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     failed       0.67      0.99      0.80     59307\n",
      " successful       0.93      0.30      0.45     40132\n",
      "\n",
      "avg / total       0.78      0.71      0.66     99439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes model\n",
    "\n",
    "t1 = time.process_time()\n",
    "NB = GaussianNB()\n",
    "NB.fit(x_train, y_train)\n",
    "predictions = NB.predict(x_test)\n",
    "t2 = time.process_time()\n",
    "print(t2 - t1, 's')\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3125 s\n",
      "0.999859210169\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     failed       1.00      1.00      1.00     59307\n",
      " successful       1.00      1.00      1.00     40132\n",
      "\n",
      "avg / total       1.00      1.00      1.00     99439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression model\n",
    "\n",
    "t1 = time.process_time()\n",
    "LR = LogisticRegression()\n",
    "LR.fit(x_train, y_train)\n",
    "predictions = LR.predict(x_test)\n",
    "t2 = time.process_time()\n",
    "print(t2 - t1, 's')\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.34375 s\n",
      "0.606864509901\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     failed       0.60      1.00      0.75     59307\n",
      " successful       0.98      0.03      0.05     40132\n",
      "\n",
      "avg / total       0.76      0.61      0.47     99439\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear Discriminant Analysis model\n",
    "\n",
    "t1 = time.process_time()\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "LDA.fit(x_train, y_train)\n",
    "predictions = LDA.predict(x_test)\n",
    "t2 = time.process_time()\n",
    "print(t2 - t1, 's')\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion Notes ##\n",
    "\n",
    "### Feature Analysis\n",
    "\n",
    "* First, we put our focus on several features that can possibly affect the final state:\n",
    "\n",
    " __backers, pledged (usd_pledged and usd_pledged_real), and goal(usd_goal_real)__\n",
    " \n",
    " \n",
    "* Based on the data preprocessing and feature importance ranking shown above, we get:\n",
    "```\n",
    " 1) usd_pledged_real                0.231361\n",
    " 2) pledged                         0.221913\n",
    " 3) backers                         0.191015\n",
    " 4) usd_goal_real                   0.151379\n",
    " 5) goal                            0.130362\n",
    " 6) usd pledged                     0.073971\n",
    " ```\n",
    " \n",
    " I choose three features 'usd_pleadged_real', 'backers' and 'usd_goal_real' as major features for classification.\n",
    " \n",
    "### Model Evaluation\n",
    " \n",
    " * Several commonly used models (Logistic Regression, Decision Tree, Linear Discriminant Analysis, K Nearest Neighbors, Naive Bayes and SVM) are selected as comparison.\n",
    " * For this application case, we need algorithms with high accuracy and high precision. The reason we choose precision is the main cost comes from False Positive (projects predicted as successful but failed in the end). So here Linear SVC, KNN, DT and LR are possible candidates.\n",
    " * According to the prediction performance and processing time, Decision Tree (DT) is chosen as the desirable model for this case.\n",
    " \n",
    "### Model Output\n",
    "\n",
    "* Finally, the selected model is trained with the complete dataset and saved as file using 'joblib'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_prediction/trained_model.m']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final training with the whole dataset\n",
    "DT.fit(x,y)\n",
    "\n",
    "# output and save the trained model\n",
    "joblib.dump(DT, 'my_prediction/trained_model.m')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you may test the model with other testing sets here\n",
    "# clf = joblib.load('my_prediction/trained_model.m')\n",
    "# predictions = clf.predict(x)\n",
    "# print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
